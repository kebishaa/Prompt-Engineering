#  Prompt Engineering: In-context learning with GPT-3 and other Large Language Models

![Gpt-3](https://www.sigmoid.com/wp-content/uploads/2020/08/sigmoid-blog-gpt-800x281.jpg)

## About

GPT3 is an autoregressive language model that uses deep learning to produce
human-like text.
The architecture is a standard transformer network(with free engineering tweaks) with
the unprecedented size of 2048-token-long context and 175 billion parameters(requiring
800 GB of storage ) The training method is “generative pretraining”, meaning that it is
trained to predict what the next token is. The model demonstrated strong few-shot
learning on many text-based tasks.The quality of the text generated by GPT-3 is so high
that it can be difficult to determine whether or not it was written by a human, which has
both benefits and risks.

## Objectives

Large Language Models coupled with multiple AI capabilities are able to generate images
and text, and also approach/achieve human level performance on a number of tasks. The
world is going through a revolution in art (DALL-E, MidJourney, Imagine, etc.), science
(AlphaFold), medicine, and other key areas, and this approach is playing a role in this
revolution.

## Data
## The columns of the data are

- **Domain** - the base URL or a reference to the source these item comes from 
- **Title** - title of the item - the content of the item
- **Description** - the content of the item
- **Body** - the content of the item
- **Link**- URL to the item source (it may not functional anymore sometime)
- **Timestamp** - timestamp that this item was collected at
- **Analyst_Average_Score**-  target variable - the score to be estimated 
- **Analyst_Rank** - score as rank
- **Reference_Final_Score** - Not relevant for now - it is a transformed quantity
## The tasks
1 Understand the algorithms and techniques that goes into building large language models 
2 Design a pipeline that takes a news item (e.g. title +  description + body) or a job description and returns a score for the news item and list of entities
3 Write a flask or fastapi backend. The API should have at least two endpoints 
         /bnewscore - for scoring  breaking news that may lead to public unrest
         /jdentities - for extracting entities from job description
